{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Unreleased Models with Ollama\n",
    "\n",
    "This notebook shows how to evaluate models not yet available through API providers by running them locally with Ollama.\n",
    "\n",
    "We'll use [Nemotron-3-Nano-30B-A3B](https://huggingface.co/unsloth/Nemotron-3-Nano-30B-A3B-GGUF) as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Ollama\n",
    "\n",
    "**macOS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o /tmp/Ollama.zip \"https://ollama.com/download/Ollama-darwin.zip\" && \\\n",
    "    unzip -o /tmp/Ollama.zip -d /Applications/ && \\\n",
    "    rm /tmp/Ollama.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linux:** `curl -fsSL https://ollama.com/install.sh | sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open /Applications/Ollama.app  # macOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_dir = \"/tmp/nemotron\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Download IQ4_XS quantization (18.2 GB)\n",
    "!curl -L -o /tmp/nemotron/Nemotron-3-Nano-30B-A3B-IQ4_XS.gguf \\\n",
    "    \"https://huggingface.co/unsloth/Nemotron-3-Nano-30B-A3B-GGUF/resolve/main/Nemotron-3-Nano-30B-A3B-IQ4_XS.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Modelfile\n",
    "modelfile = '''FROM /tmp/nemotron/Nemotron-3-Nano-30B-A3B-IQ4_XS.gguf\n",
    "\n",
    "TEMPLATE \"\"\"{{- if .System }}{{ .System }}\n",
    "{{- end }}\n",
    "{{- range .Messages }}\n",
    "{{- if eq .Role \"user\" }}<|start_header_id|>user<|end_header_id|>\n",
    "{{ .Content }}<|eot_id|>\n",
    "{{- else if eq .Role \"assistant\" }}<|start_header_id|>assistant<|end_header_id|>\n",
    "{{ .Content }}<|eot_id|>\n",
    "{{- end }}\n",
    "{{- end }}\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "PARAMETER stop \"<|eot_id|>\"\n",
    "PARAMETER stop \"<|end_of_text|>\"\n",
    "'''\n",
    "\n",
    "with open(\"/tmp/nemotron/Modelfile\", \"w\") as f:\n",
    "    f.write(modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama create nemotron-nano -f /tmp/nemotron/Modelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OLLAMA_BASE_URL\"] = \"http://localhost:11434/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warm up the model (keeps it loaded for 60 minutes)\n",
    "!ollama run nemotron-nano --keepalive 60m \"hi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"ollama/nemotron-nano\"\n",
    "LIMIT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/.local/bin/uv run inspect eval \\\n",
    "    src/open_telco/teleqna/teleqna.py \\\n",
    "    src/open_telco/telemath/telemath.py \\\n",
    "    src/open_telco/telelogs/telelogs.py \\\n",
    "    src/open_telco/three_gpp/three_gpp.py \\\n",
    "    --model {MODEL} \\\n",
    "    --limit {LIMIT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/.local/bin/uv run inspect view start --log-dir logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
